{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b82869",
   "metadata": {},
   "source": [
    "# Yandex.Cloud\n",
    "\n",
    "Панель управления облаком через браузер - https://cloud.yandex.ru\n",
    "\n",
    "Каждому студенту выделена отдельная директория в общем облаке. Внутри этой директории можно создавать различные облачные ресурсы. Все операции для работы с облаком можно проводить из браузера или из консоли.\n",
    "\n",
    "Чтобы работать из консоли, необходимо установить утилиту **yc**.\n",
    "\n",
    "Полный гайд есть на сайте - https://cloud.yandex.ru/docs/cli/quickstart\n",
    "\n",
    "#### Но перед этим, если у вас Windows...\n",
    "\n",
    "1. Мы вам искренне соболезнуем\n",
    "2. Установите на компьютер WSL (Windows Subsystem Linux) - https://docs.microsoft.com/ru-ru/windows/wsl/install . Если это у вас успешно получится, то из этой среды вы сможете делать все те действия, что описываются далее\n",
    "\n",
    "Краткая выжимка того, что нужно сделать, чтобы все начало работать.\n",
    "\n",
    "1) Устанавливаем клиент \n",
    "\n",
    "```bash\n",
    "curl https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash\n",
    "```\n",
    "\n",
    "2) Авторизуемся \n",
    "\n",
    "```bash\n",
    "yc init\n",
    "```\n",
    "\n",
    "В процессе авторизации вам нужно будет открыть браузер, авторизоваться в облаке с помощью вашей почты на yandex.ru (которую вы указывали в форме), перекопировать токен и выбрать вашу директорию для lsml.\n",
    "\n",
    "3) Проверяем, что все сработало \n",
    "\n",
    "```bash\n",
    "yc config list\n",
    "```\n",
    "\n",
    "4) Вы великолепны!\n",
    "\n",
    "Для дальнейшей работы с облаком вам может потребоваться ssh ключ. Если он у вас есть (посмотрите в `~/.ssh`) , то все отлично! Если нет, то сгенерируйте ключ (хорошая инструкция например от github - https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bfdb3",
   "metadata": {},
   "source": [
    "# Подготавливаем облако к продуктивной работе\n",
    "\n",
    "## Сервисный аккаунт\n",
    "\n",
    "В вашем каталоге уже должен быть настроенный сервисный аккаунт `lsml2022account-x`. Используйте его во всех ресурсах, где требуется его указать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ac930",
   "metadata": {},
   "source": [
    "## Настраиваем сеть\n",
    "\n",
    "Без настроенной сети работать с облаком будет затруднительно. Поэтому давайте настроем сеть в облаке.\n",
    "\n",
    "Идем в `Virtual Private Cloud`, жмем создать сеть, называем ее `default` и кликаем `Создать подсети`.\n",
    "\n",
    "Потом идем в подсети и для `default-ru-central1-a` включаем NAT (это нужно, чтобы мы потом могли подключиться с ноутбука к кластеру).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6bfda",
   "metadata": {},
   "source": [
    "## Настраиваем хранилище\n",
    "\n",
    "Вся наша бигдата должна где-то хранится. Для этого создадим бакет в `Object Storage`. Название бакету можете выдать любое. Единственное ограничение - оно должно быть унивальным во всем Яндекс.Облаке.\n",
    "\n",
    "Выставляйте ему следующие настройки\n",
    "\n",
    "* Лимит - 1 ТБ\n",
    "* Доступ на чтение объектов - публичный (это нужно, чтобы мы потом могли проверить ваши домашки)\n",
    "* Доступ к списку объектов - ограниченный\n",
    "* Доступ на чтение настроек - ограниченный\n",
    "* Класс хранилища - стандартное\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dfcd0d",
   "metadata": {},
   "source": [
    "## Настраиваем кластер \n",
    "\n",
    "Время настраивать сам кластер. Идем в `Data Proc`. Кстати, в ```yandex-cloud-terraform``` лежит конфиг терраформа, который поможет поднять все гораздо легче.\n",
    "\n",
    "* Выключаем `TEZ`\n",
    "* Включаем `Livy`\n",
    "* Зона доступности - `central1-a`\n",
    "* Имя бакета - тот, что создали до этого\n",
    "* Сеть - ту, что создали до этого\n",
    "* ssh-ключ - ваш ключ с суффиксом .pub\n",
    "* `UI Proxy` - включаем\n",
    "* Ниже можно добавить подкластер с `ComputeNode` - там можно указать, сколько машин для рассчетов добавить в кластер (для начала можно и одну, но в будущем скорее всего потребуется добавлять больше, чтобы считать задачи)\n",
    "    * Выставляйте hdd диски вместо ssd для машин, а то может не хватить на всех\n",
    "    * Сильно большие тачки лучше не создавать - парочка `s2.small` это вполне неплохой выбор для наших целей\n",
    "\n",
    "**Note:** ComputeNode - это подкластер, где можно запускать Spark поверх данных из объектоного хранилища, DataNode - это подкластер, где можно к дополнение к этому еще запускать и классический Хадуп поверх локальный данных на машине (в HDFS на машинах). На данном этапе разницы никакой - как лучше настраивать кластер мы поймем дальше по ходу курса. \n",
    "\n",
    "**Ждем...**\n",
    "\n",
    "Ребята в Яндексе постарались и поэтому кластер создается достаточно быстро, но все таки это занимает какое-то время. Более того, наливка кластера - задача не самая простая, поэтому есть шанс увидеть кластер в состоянии `Dead` - пугаться не стоит, скоро оно починится и вы с можете начать с ним работать.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ADKosm/lsml-2022-public/main/data/1/umer.png\" width=\"200px\">\n",
    "\n",
    "Когда чудо произойдет, можно провести простой тест и попробовать открыть какие-то UI Proxy.\n",
    "\n",
    "## Настраиваем Proxy машину\n",
    "\n",
    "Работы напрямую с Hadoop необходимо проворачивать с MasterNode. Из-за соображений безопасности, нельзя просто так подключится к мастер-ноде. Для того, чтобы сделать это, нам потребуется прокси.\n",
    "\n",
    "Идем в `Compute Cloud`\n",
    "\n",
    "Создаем машину минимального размера (она потребуется только для проксирования)\n",
    "\n",
    "* Зона доступности - central1-a\n",
    "* Ubuntu\n",
    "* Подсеть - central1-a\n",
    "* Сервисный аккаунт - тот самый\n",
    "* Логин - yc-user\n",
    "* ssh-ключ - тот же самый ваш публичный\n",
    "* Гарантированная доля vCPU - 20%. Это снижает расходы на тачку в ~1.5 раза\n",
    "\n",
    "После создания копируем публичный IP адрес машины и пробуем подключиться (ниже мои IP для примера - у себя используйте свои)\n",
    "\n",
    "```bash\n",
    "ssh yc-user@62.84.126.222\n",
    "```\n",
    "\n",
    "Если все хорошо, то пытаемся подключиться через прокси-машину до мастера нашего кластера. Сначала добавляем наш ключик в ssh-агент следующей командой:\n",
    "\n",
    "```bash\n",
    "ssh-add ~/.ssh/id_key\n",
    "```\n",
    "\n",
    "Дальше нам надо найти внутренний FQDN мастер ноды (его можно посмотреть, кликнув на машину мастер ноды).\n",
    "\n",
    "А теперь вишенка на торте:\n",
    "\n",
    "```bash\n",
    "ssh -A -J yc-user@62.84.126.222 ubuntu@rc1a-dataproc-m-81gv9d0a18t0dy1r.mdb.yandexcloud.net\n",
    "```\n",
    "\n",
    "Эта команда автоматически подключит нас к мастеру через прокси-сервер. Магия, да и только! Теперь можно упростить подключение, добавив в ~/.ssh/config конфигурацию нашего подключения.\n",
    "\n",
    "```\n",
    "echo <<EOF >>~/.ssh/config\n",
    "Host lsml-proxy\n",
    "\tHostName 62.84.126.222\n",
    "\tUser yc-user\n",
    "\tIdentityFile ~/.ssh/id_key\n",
    "\n",
    "Host lsml-head\n",
    "    HostName rc1a-dataproc-m-81gv9d0a18t0dy1r.mdb.yandexcloud.net\n",
    "\tUser ubuntu\n",
    "\tProxyJump lsml-proxy\n",
    "EOF\n",
    "```\n",
    "\n",
    "После этого подключение к головному узлу становится максимально простым:\n",
    "\n",
    "```bash\n",
    "ssh lsml-head\n",
    "```\n",
    "\n",
    "Проверяем, что все завелось\n",
    "```bash\n",
    "hadoop version\n",
    "\n",
    "hdfs dfs -ls /\n",
    "```\n",
    "\n",
    "Если все хорошо, давайте сразу проверим работу с `Object Storage`. \n",
    "\n",
    "Пробуем запустить комманду (`lsml2022data` - название моего бакета)\n",
    "\n",
    "```bash\n",
    "hdfs dfs -ls s3a://lsml2022data/\n",
    "```\n",
    "\n",
    "Это мы попробовали прочитать что-то из бакета. Если все прошло успешно, давайте попробуем записать что-то.\n",
    "\n",
    "```bash\n",
    "echo \"Biba\" > kuka.txt\n",
    "hdfs dfs -put kuka.txt s3a://lsml2022data/kuka.txt\n",
    "```\n",
    "\n",
    "Если все успешно прошло, то перейдите в админке облака в `Object Storage` и посмотрите в него - там должен оказаться файл kuka.txt с содержанием \"Biba\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fab322",
   "metadata": {},
   "source": [
    "## Настраиваем проект в Data Sphere\n",
    "\n",
    "Для удобного управление вычислениями в кластере, создадим проект в ДатаСфере и будем работать оттуда.\n",
    "\n",
    "При создании, заполните также \"Дополнительные параметры\":\n",
    "* Сервисный аккаунт - тот самый\n",
    "* Подсеть - default-ru-central1-a\n",
    "* Кластер `Data Proc` - тот, что создали до этого\n",
    "\n",
    "После создания Jupyter Lab создайте там новый ноутбук (и сразу дайте ему какое-то осмысленное название!) и запустите что-нибудь вроде\n",
    "\n",
    "```python\n",
    "print(\"Hello pupa, I am the lupa\")\n",
    "```\n",
    "\n",
    "После этого должна начать создаваться машина для работы ноутбука. Как только все свершится, команда должна запуститься.\n",
    "\n",
    "По умолчанию в датасфере все вычисления происходят на выделенной машине с собственным интерпретатором без кластеров и всего такого.\n",
    "\n",
    "Для того, чтобы начать запускать команды в контексте спарка, необходимо добавить специальный макрос в начале клетки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81be21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on Livy\n"
     ]
    }
   ],
   "source": [
    "#!spark\n",
    "\n",
    "print(\"Run on Livy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark\n",
    "\n",
    "data = sc.textFile(\"s3a://lsml2022data/kuka.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09416977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark\n",
    "\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ed5da",
   "metadata": {},
   "source": [
    "После запуска этих ячеек спарк должен был прочитать данные из созданного нами ранее файла."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e070d",
   "metadata": {},
   "source": [
    "## Действия после работы\n",
    "\n",
    "Работающий кластер кушает много денег. Поэтому чтобы они не закончились, останавливайте кластер после использования. Остальные запчасти в облаке можно не трогать, они кушают мало денег.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ADKosm/lsml-2022-public/main/data/1/5a3867946daef3.6346339815136459724493.png\">\n",
    "\n",
    "\n",
    "# Аплодисменты \n",
    "\n",
    "Поздравляю, теперь вы готовы к сражению с биг датой! **И не забудьте погасить свой кластер.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b88d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
